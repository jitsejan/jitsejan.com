{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-req\n",
    "1. Setup a simple SFTP server on your ([Ubuntu](https://www.digitalocean.com/community/tutorials/how-to-enable-sftp-without-shell-access-on-ubuntu-16-04)) machine.\n",
    "2. Add a file with the following content:\n",
    "\n",
    "```bash\n",
    "$ cat /home/ftpuser/data/sample.psv\n",
    "title|name|age\n",
    "mr|john doe|34\n",
    "mrs|jane doe|30\n",
    "```\n",
    "\n",
    "3. ZIP the PSV file.\n",
    "\n",
    "```bash\n",
    "$ zip /home/ftpuser/data/testpsv.zip /home/ftpuser/data/sample.psv\n",
    "```\n",
    "\n",
    "4. Have Spark installed\n",
    "5. Have the [JAR](https://mvnrepository.com/artifact/com.springml/spark-sftp) from https://github.com/springml/spark-sftp available in your Spark JAR directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://repo1.maven.org/maven2/com/springml/sftp.client/1.0.3/sftp.client-1.0.3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://repo1.maven.org/maven2/com/springml/spark-sftp_2.10/1.0.2/spark-sftp_2.10-1.0.2.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "import os\n",
    "\n",
    "os.environ['HADOOP_HOME'] = '/opt/hadoop/'\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'python3'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python3'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/opt/hadoop/lib/native'\n",
    "os.environ['SPARK_DIST_CLASSPATH'] = \"/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*\"\n",
    "os.environ['SPARK_HOME'] = '/opt/spark/'\n",
    "\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setAppName(\"Spark SFTP Test\")\n",
    "    .set(\"spark.hadoop.fs.sftp.impl\", \"org.apache.hadoop.fs.sftp.SFTPFileSystem\")\n",
    ")\n",
    "sc = SparkContext(conf=conf).getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a file directly into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+\n",
      "| _c0|_c1|_c2|\n",
      "+----+---+---+\n",
      "|john|doe| 35|\n",
      "|jane|doe| 32|\n",
      "+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext\\\n",
    "    .read\\\n",
    "    .format(\"com.springml.spark.sftp\")\\\n",
    "    .option(\"host\", os.environ.get('FTP_HOST'))\\\n",
    "    .option(\"username\", os.environ.get('FTP_USER'))\\\n",
    "    .option(\"password\", os.environ.get('FTP_PASS'))\\\n",
    "    .option(\"fileType\", \"csv\")\\\n",
    "    .option(\"delimiter\", \"|\")\\\n",
    "    .option(\"quote\", \"\\\"\")\\\n",
    "    .option(\"escape\", \"\\\\\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"false\")\\\n",
    "    .option(\"header\", \"false\")\\\n",
    "    .load(\"/data/sample.psv\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a file as binary file and transform into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---+\n",
      "|first_name|last_name|age|\n",
      "+----------+---------+---+\n",
      "|      john|      doe| 35|\n",
      "|      jane|      doe| 32|\n",
      "+----------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"first_name\", StringType()),\n",
    "    StructField(\"last_name\", StringType()),\n",
    "    StructField(\"age\", StringType())\n",
    "])\n",
    "file_path = 'data/sample.psv'\n",
    "\n",
    "psv_df = sc\\\n",
    "    .binaryFiles(f\"sftp://{os.environ.get('FTP_USER')}:{os.environ.get('FTP_PASS')}@{os.environ.get('FTP_HOST')}/{file_path}\")\\\n",
    "    .map(lambda row: row[1].decode('utf-8').strip())\\\n",
    "    .flatMap(lambda row: str(row).split('\\n'))\\\n",
    "    .map(lambda row: str(row).split('|'))\\\n",
    "    .toDF(schema=schema)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract a ZIP archive and parse the content into a dataframe\n",
    "The following snippet extracts a ZIP file in memory and returns the content of the first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---+\n",
      "|first_name|last_name|age|\n",
      "+----------+---------+---+\n",
      "|      john|      doe| 35|\n",
      "|      jane|      doe| 32|\n",
      "+----------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import zipfile\n",
    "\n",
    "def zip_extract(row):\n",
    "    file_path, content = row\n",
    "    zfile = zipfile.ZipFile(io.BytesIO(content), \"r\")\n",
    "    files = [i for i in zfile.namelist()]\n",
    "    return zfile.open(files[0]).read().decode(\"utf-8\", errors='ignore')\n",
    "\n",
    "file_path = 'data/testpsv.zip'\n",
    "\n",
    "psv_df = sc\\\n",
    "    .binaryFiles(f\"sftp://{os.environ.get('FTP_USER')}:{os.environ.get('FTP_PASS')}@{os.environ.get('FTP_HOST')}/{file_path}\")\\\n",
    "    .map(zip_extract)\\\n",
    "    .map(lambda row: row.strip())\\\n",
    "    .flatMap(lambda row: str(row).split('\\n'))\\\n",
    "    .map(lambda row: str(row).split('|'))\\\n",
    "    .toDF(schema=schema)\\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
